{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objective : classify a playlist name with AutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# help Idk stuff corner\n",
    "###\n",
    "\n",
    "# https://cloud.google.com/natural-language/automl/docs/tutorial\n",
    "# !pip install google-cloud-automl\n",
    "\n",
    "# it seems BigQuery ML *is* AutoML so that's grand\n",
    "# https://cloud.google.com/bigquery-ml/\n",
    "# docs/reference/standard-sql/bigqueryml-syntax-create-automl\n",
    "\n",
    "# how to predict once model is created ?\n",
    "# https://github.com/googleapis/python-automl/blob/main/samples/snippets/translate_predict.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "from google.cloud import bigquery\n",
    "from google.cloud import storage\n",
    "from google.cloud import automl\n",
    "\n",
    "from botocore.exceptions import ClientError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "home = os.path.expanduser('~')\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=f\"{home}/.config/gcloud/alpine-beacon-336222-c6a1c087e3ef.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more cringe binge\n",
    "with open(\"sql/dml/count_playlist_names.sql\", \"r\") as the_file:\n",
    "    the_qRy = \"\"\n",
    "    while True:\n",
    "        line = the_file.readline()\n",
    "        if line == \"\":\n",
    "            break\n",
    "        else:\n",
    "            the_qRy = the_qRy + \" \" + line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = bigquery.Client()\n",
    "project = client.project\n",
    "dataset_id = \"{}.music\".format(project)\n",
    "dataset = bigquery.Dataset(dataset_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "qry_job = client.query(the_qRy)\n",
    "results = qry_job.result()\n",
    "df = results.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>78</td>\n",
       "      <td>Country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54</td>\n",
       "      <td>Christmas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54</td>\n",
       "      <td>Chill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>Rap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48</td>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>36</td>\n",
       "      <td>chill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>36</td>\n",
       "      <td>country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>36</td>\n",
       "      <td>throwback</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>36</td>\n",
       "      <td>ClassicRock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>30</td>\n",
       "      <td>Workout</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count         name\n",
       "0     78      Country\n",
       "1     54    Christmas\n",
       "2     54        Chill\n",
       "3     48          Rap\n",
       "4     48         Rock\n",
       "5     36        chill\n",
       "6     36      country\n",
       "7     36    throwback\n",
       "8     36  ClassicRock\n",
       "9     30      Workout"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now isolate a table with playlist name in this list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevants = df.head(20).name.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Country',\n",
       " 'Christmas',\n",
       " 'Chill',\n",
       " 'Rap',\n",
       " 'Rock',\n",
       " 'chill',\n",
       " 'country',\n",
       " 'throwback',\n",
       " 'ClassicRock',\n",
       " 'Workout',\n",
       " '����',\n",
       " 'lit',\n",
       " 'workout',\n",
       " '2017',\n",
       " 'calm',\n",
       " 'party',\n",
       " 'Sleep',\n",
       " 'Oldies',\n",
       " '❤️',\n",
       " 'november']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more cringe binge\n",
    "with open(\"sql/ddl/yoink_relevants.sql\", \"r\") as the_file:\n",
    "    the_relevant_qRy = \"\"\n",
    "    while True:\n",
    "        line = the_file.readline()\n",
    "        if line == \"\":\n",
    "            break\n",
    "        else:\n",
    "            the_relevant_qRy = the_relevant_qRy + \" \" + line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables contained in 'alpine-beacon-336222.music':\n",
      "alpine-beacon-336222.music.relevants\n",
      "deleting relevants . . . \n",
      "d o n e\n"
     ]
    }
   ],
   "source": [
    "# delete table if it exists\n",
    "tables = client.list_tables(dataset_id)  # Make an API request.\n",
    "\n",
    "print(\"Tables contained in '{}':\".format(dataset_id))\n",
    "for table in tables:\n",
    "    if table.table_id == \"relevants\": \n",
    "        fqn = \"{}.{}.{}\".format(table.project, table.dataset_id, table.table_id)\n",
    "        print(fqn)\n",
    "        print(\"deleting relevants . . . \")\n",
    "        client.delete_table(table)\n",
    "        print(\"d o n e\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables now contained in 'alpine-beacon-336222.music':\n",
      "alpine-beacon-336222.music.slices\n"
     ]
    }
   ],
   "source": [
    "tables = client.list_tables(dataset_id)  # Make an API request.\n",
    "\n",
    "print(\"Tables now contained in '{}':\".format(dataset_id))\n",
    "for table in tables:\n",
    "    print(\"{}.{}.{}\".format(table.project, table.dataset_id, table.table_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    create_table_job = client.query(the_relevant_qRy)\n",
    "    create_table_job.result()\n",
    "except ClientError as eek:\n",
    "    for eRr in create_table.errors:\n",
    "        print(f\"{eRr} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " CREATE OR REPLACE MODEL `music.classification_model2`\n",
      " OPTIONS\n",
      "   (model_type='AUTOML_CLASSIFIER',\n",
      "   input_label_cols=['name']) AS\n",
      " SELECT \n",
      "     name,\n",
      "     collaborative,\n",
      "     artist_name,\n",
      "     track_name,\n",
      "     album_name,\n",
      "     num_edits,\n",
      "     description,\n",
      "     num_artists,\n",
      "     modified_at\n",
      " FROM (\n",
      " SELECT *\n",
      "     FROM `alpine-beacon-336222.music.relevants`,\n",
      "     UNNEST(tracks) as TRK\n",
      " )\n",
      " LIMIT 1000;\n"
     ]
    }
   ],
   "source": [
    "with open(\"sql/models/classification_model.sql\", \"r\") as the_file:\n",
    "    model_qRy = \"\"\n",
    "    while True:\n",
    "        line = the_file.readline()\n",
    "        if line == \"\":\n",
    "            break\n",
    "        else:\n",
    "            model_qRy = model_qRy + \" \" + line\n",
    "\n",
    "print(model_qRy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "BadRequest",
     "evalue": "400 Failed to calculate avg_string_length since the entries in corresponding column 'description' are all NULLs.\n\nLocation: US\nJob ID: 05378acc-5e23-4270-a753-6cd2a005b6aa\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadRequest\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/google/cloud/bigquery/job/query.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, page_size, max_results, retry, timeout, start_index, job_retry)\u001b[0m\n\u001b[1;32m   1496\u001b[0m                 \u001b[0mdo_get_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjob_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo_get_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1498\u001b[0;31m             \u001b[0mdo_get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGoogleAPICallError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/google/api_core/retry.py\u001b[0m in \u001b[0;36mretry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    289\u001b[0m                 \u001b[0msleep_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_deadline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m                 \u001b[0mon_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mon_error\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m             )\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/google/api_core/retry.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, deadline, on_error)\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msleep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msleep_generator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/google/cloud/bigquery/job/query.py\u001b[0m in \u001b[0;36mdo_get_result\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1486\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_job_retry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjob_retry\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1488\u001b[0;31m                 \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQueryJob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1490\u001b[0m                 \u001b[0;31m# Since the job could already be \"done\" (e.g. got a finished job\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/google/cloud/bigquery/job/base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, retry, timeout)\u001b[0m\n\u001b[1;32m    726\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mretry\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mDEFAULT_RETRY\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"retry\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mretry\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_AsyncJob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcancelled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/google/api_core/future/polling.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout, retry)\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0;31m# pylint: disable=raising-bad-type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0;31m# Pylint doesn't recognize that this is valid in this case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBadRequest\u001b[0m: 400 Failed to calculate avg_string_length since the entries in corresponding column 'description' are all NULLs.\n\nLocation: US\nJob ID: 05378acc-5e23-4270-a753-6cd2a005b6aa\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_query_job = client.query(model_qRy)\n",
    "model_results = model_query_job.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_datasets(project_id):\n",
    "    \"\"\"List datasets.\"\"\"\n",
    "\n",
    "    client = automl.AutoMlClient()\n",
    "    # A resource that represents Google Cloud Platform location.\n",
    "    project_location = f\"projects/{project_id}/locations/us-central1\"\n",
    "\n",
    "    # List all the datasets available in the region.\n",
    "    request = automl.ListDatasetsRequest(parent=project_location, filter=\"\")\n",
    "    response = client.list_datasets(request=request)\n",
    "\n",
    "    print(\"List of datasets:\")\n",
    "    for dataset in response:\n",
    "        print(\"Dataset name: {}\".format(dataset.name))\n",
    "        print(\"Dataset id: {}\".format(dataset.name.split(\"/\")[-1]))\n",
    "        print(\"Dataset display name: {}\".format(dataset.display_name))\n",
    "        print(\"Dataset create time: {}\".format(dataset.create_time))\n",
    "        # [END automl_language_sentiment_analysis_list_datasets]\n",
    "        # [END automl_language_text_classification_list_datasets]\n",
    "        # [END automl_translate_list_datasets]\n",
    "        # [END automl_vision_classification_list_datasets]\n",
    "        # [END automl_vision_object_detection_list_datasets]\n",
    "        print(\n",
    "            \"Text extraction dataset metadata: {}\".format(\n",
    "                dataset.text_extraction_dataset_metadata\n",
    "            )\n",
    "        )\n",
    "        # [END automl_language_entity_extraction_list_datasets]\n",
    "\n",
    "        # [START automl_language_sentiment_analysis_list_datasets]\n",
    "        print(\n",
    "            \"Text sentiment dataset metadata: {}\".format(\n",
    "                dataset.text_sentiment_dataset_metadata\n",
    "            )\n",
    "        )\n",
    "        # [END automl_language_sentiment_analysis_list_datasets]\n",
    "\n",
    "        # [START automl_language_text_classification_list_datasets]\n",
    "        print(\n",
    "            \"Text classification dataset metadata: {}\".format(\n",
    "                dataset.text_classification_dataset_metadata\n",
    "            )\n",
    "        )\n",
    "        # [END automl_language_text_classification_list_datasets]\n",
    "\n",
    "        # [START automl_translate_list_datasets]\n",
    "        print(\"Translation dataset metadata:\")\n",
    "        print(\n",
    "            \"\\tsource_language_code: {}\".format(\n",
    "                dataset.translation_dataset_metadata.source_language_code\n",
    "            )\n",
    "        )\n",
    "        print(\n",
    "            \"\\ttarget_language_code: {}\".format(\n",
    "                dataset.translation_dataset_metadata.target_language_code\n",
    "            )\n",
    "        )\n",
    "        # [END automl_translate_list_datasets]\n",
    "\n",
    "        # [START automl_vision_classification_list_datasets]\n",
    "        print(\n",
    "            \"Image classification dataset metadata: {}\".format(\n",
    "                dataset.image_classification_dataset_metadata\n",
    "            )\n",
    "        )\n",
    "        # [END automl_vision_classification_list_datasets]\n",
    "\n",
    "        # [START automl_vision_object_detection_list_datasets]\n",
    "        print(\n",
    "            \"Image object detection dataset metadata: {}\".format(\n",
    "                dataset.image_object_detection_dataset_metadata\n",
    "            )\n",
    "        )\n",
    "        # [END automl_vision_object_detection_list_datasets]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of datasets:\n",
      "Dataset name: projects/986744994995/locations/us-central1/datasets/TCN4345301289052143616\n",
      "Dataset id: TCN4345301289052143616\n",
      "Dataset display name: music\n",
      "Dataset create time: 2022-02-26 00:26:22.581011+00:00\n",
      "Text extraction dataset metadata: \n",
      "Text sentiment dataset metadata: \n",
      "Text classification dataset metadata: classification_type: MULTICLASS\n",
      "\n",
      "Translation dataset metadata:\n",
      "\tsource_language_code: \n",
      "\ttarget_language_code: \n",
      "Image classification dataset metadata: \n",
      "Image object detection dataset metadata: \n"
     ]
    }
   ],
   "source": [
    "project_id = client.project\n",
    "list_datasets(project_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
