{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"people from different cultures can agree that a song is angry, but can differ on whether that feeling is positive or negative\" - some random study I didn't citeimsosry\n",
    "\"creativity is the residue of wasted time\" - Einstein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valence -> culture specific; positive or negative values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!python -m pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!pip install --upgrade google-cloud\n",
    "!pip install --upgrade google-cloud-bigquery\n",
    "!pip install --upgrade google-cloud-storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from google.cloud import bigquery\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not secure but I'm lazy, steal what you must\n",
    "home = os.path.expanduser('~')\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=f\"{home}/.config/gcloud/alpine-beacon-336222-c6a1c087e3ef.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/mpd.slice.54000-54999.json\", \"r\") as the_jfile:\n",
    "    data = json.load(the_jfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top playlist name len found to be 66\n",
      "top track name len found to be 202\n",
      "top artist name len found to be 91\n",
      "top uri len found to be 37\n",
      "top album name len found to be 151\n"
     ]
    }
   ],
   "source": [
    "name_top_len = 0\n",
    "track_name_top_len = 0\n",
    "artist_top_len = 0\n",
    "uri_top_len = 0\n",
    "album_name_top_len = 0\n",
    "\n",
    "idx = 0\n",
    "\n",
    "#dict_keys(['name', 'collaborative', 'pid', 'modified_at', 'num_tracks', 'num_albums', 'num_followers', 'tracks', 'num_edits', 'duration_ms', 'num_artists'])\n",
    "\n",
    "while idx < len(data[\"playlists\"]):\n",
    "    for KEY, VAL in data[\"playlists\"][idx].items():\n",
    "#        print(f\"{KEY} : {VAL}\")\n",
    "        if KEY==\"name\":\n",
    "            cur_len = len(VAL)\n",
    "            if cur_len > name_top_len:\n",
    "                name_top_len = cur_len\n",
    "        elif KEY == \"tracks\":\n",
    "            tracks = data[\"playlists\"][idx][\"tracks\"]\n",
    "            for track in tracks:\n",
    "                cur_len = len(track[\"track_name\"])                \n",
    "                if cur_len > track_name_top_len:\n",
    "                    track_name_top_len = cur_len\n",
    "                cur_len = len(track[\"artist_name\"])\n",
    "                if cur_len > artist_top_len:\n",
    "                    artist_top_len = cur_len\n",
    "                cur_len = len(track[\"track_uri\"]) #36\n",
    "                if cur_len > uri_top_len:\n",
    "                    uri_top_len = cur_len\n",
    "                cur_len = len(track[\"artist_uri\"]) #37\n",
    "                if cur_len > uri_top_len:\n",
    "                    uri_top_len = cur_len\n",
    "                cur_len = len(track[\"album_uri\"]) #36\n",
    "                if cur_len > uri_top_len:\n",
    "                    uri_top_len = cur_len\n",
    "                cur_len = len(track[\"album_name\"])\n",
    "                if cur_len > album_name_top_len:\n",
    "                    album_name_top_len = cur_len\n",
    "    idx += 1\n",
    "\n",
    "#print(idx)\n",
    "        \n",
    "print(\"top playlist name len found to be {}\".format(name_top_len))\n",
    "print(\"top track name len found to be {}\".format(track_name_top_len))\n",
    "print(f\"top artist name len found to be {artist_top_len}\")\n",
    "print(f\"top uri len found to be {uri_top_len}\")\n",
    "print(\"top album name len found to be {}\".format(album_name_top_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in conclusion, stop changing things\n",
    "# https://big-data-demystified.ninja/2020/04/12/how-to-debug-error-while-reading-data-error-message-failed-to-parse-json-unexpected-end-of-string-unexpected-end-of-string-expected-key/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sed 's/ //g' data/mpd.slice.54000-54999.json > data/mpd.slice.54000-54999_test.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat data/mpd.slice.54000-54999.json | tr '\\n' ' ' > data/mpd.slice.54000-54999_giraff.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sed 's/ //g' data/mpd.slice.54000-54999.json | tr '\\n' ' '> data/mpd.slice.54000-54999_hi.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you experience problems with multiprocessing on MacOS, they might be related to https://bugs.python.org/issue33725. You can disable multiprocessing by editing your .boto config or by adding the following flag to your command: `-o \"GSUtil:parallel_process_count=1\"`. Note that multithreading is still available even if you disable multiprocessing.\n",
      "\n",
      "Copying file://data/mpd.slice.54000-54999_hi.json [Content-Type=application/json]...\n",
      "/ [1/1 files][ 18.2 MiB/ 18.2 MiB] 100% Done                                    \n",
      "Operation completed over 1 objects/18.2 MiB.                                     \n"
     ]
    }
   ],
   "source": [
    "!gsutil -m cp data/mpd.slice.54000-54999_hi.json gs://the-bourgeoisie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you experience problems with multiprocessing on MacOS, they might be related to https://bugs.python.org/issue33725. You can disable multiprocessing by editing your .boto config or by adding the following flag to your command: `-o \"GSUtil:parallel_process_count=1\"`. Note that multithreading is still available even if you disable multiprocessing.\n",
      "\n",
      "Copying file://data/mpd.slice.54000-54999_giraff.json [Content-Type=application/json]...\n",
      "| [1/1 files][ 31.8 MiB/ 31.8 MiB] 100% Done                                    \n",
      "Operation completed over 1 objects/31.8 MiB.                                     \n"
     ]
    }
   ],
   "source": [
    "!gsutil -m cp data/mpd.slice.54000-54999_giraff.json gs://the-bourgeoisie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you experience problems with multiprocessing on MacOS, they might be related to https://bugs.python.org/issue33725. You can disable multiprocessing by editing your .boto config or by adding the following flag to your command: `-o \"GSUtil:parallel_process_count=1\"`. Note that multithreading is still available even if you disable multiprocessing.\n",
      "\n",
      "Copying file://data/mpd.slice.54000-54999_test.json [Content-Type=application/json]...\n",
      "/ [1/1 files][ 18.2 MiB/ 18.2 MiB] 100% Done                                    \n",
      "Operation completed over 1 objects/18.2 MiB.                                     \n"
     ]
    }
   ],
   "source": [
    "!gsutil -m cp data/mpd.slice.54000-54999_test.json gs://the-bourgeoisie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpine-beacon-336222\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "# Construct a BigQuery client object.\n",
    "client = bigquery.Client()\n",
    "\n",
    "print(client.project)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO(developer): Set dataset_id to the ID of the dataset to create.\n",
    "dataset_id = \"{}.music\".format(client.project)\n",
    "\n",
    "# Construct a full Dataset object to send to the API.\n",
    "dataset = bigquery.Dataset(dataset_id)\n",
    "\n",
    "# TODO(developer): Specify the geographic location where the dataset should reside.\n",
    "dataset.location = \"US\"\n",
    "\n",
    "# Send the dataset to the API for creation, with an explicit timeout.\n",
    "# Raises google.api_core.exceptions.Conflict if the Dataset already\n",
    "# exists within the project.\n",
    "dataset = client.create_dataset(dataset, timeout=30)  # Make an API request.\n",
    "print(\"Created dataset {}.{}\".format(client.project, dataset.dataset_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: the-bourgeoisie\n",
      "Name: the-bourgeoisie\n",
      "Storage Class: STANDARD\n",
      "Location: US\n",
      "Location Type: multi-region\n",
      "Cors: []\n",
      "Default Event Based Hold: False\n",
      "Default KMS Key Name: None\n",
      "Metageneration: 1\n",
      "Public Access Prevention: inherited\n",
      "Retention Effective Time: None\n",
      "Retention Period: None\n",
      "Retention Policy Locked: None\n",
      "Requester Pays: False\n",
      "Self Link: https://www.googleapis.com/storage/v1/b/the-bourgeoisie\n",
      "Time Created: 2022-02-24 20:23:38.300000+00:00\n",
      "Versioning Enabled: False\n",
      "Labels: {}\n"
     ]
    }
   ],
   "source": [
    "bucket_name=\"the-bourgeoisie\"\n",
    "    \n",
    "    \n",
    "from google.cloud import storage\n",
    "\n",
    "\n",
    "def bucket_metadata(bucket_name):\n",
    "    \"\"\"Prints out a bucket's metadata.\"\"\"\n",
    "    # bucket_name = 'your-bucket-name'\n",
    "\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.get_bucket(bucket_name)\n",
    "\n",
    "    print(f\"ID: {bucket.id}\")\n",
    "    print(f\"Name: {bucket.name}\")\n",
    "    print(f\"Storage Class: {bucket.storage_class}\")\n",
    "    print(f\"Location: {bucket.location}\")\n",
    "    print(f\"Location Type: {bucket.location_type}\")\n",
    "    print(f\"Cors: {bucket.cors}\")\n",
    "    print(f\"Default Event Based Hold: {bucket.default_event_based_hold}\")\n",
    "    print(f\"Default KMS Key Name: {bucket.default_kms_key_name}\")\n",
    "    print(f\"Metageneration: {bucket.metageneration}\")\n",
    "    print(\n",
    "        f\"Public Access Prevention: {bucket.iam_configuration.public_access_prevention}\"\n",
    "    )\n",
    "    print(f\"Retention Effective Time: {bucket.retention_policy_effective_time}\")\n",
    "    print(f\"Retention Period: {bucket.retention_period}\")\n",
    "    print(f\"Retention Policy Locked: {bucket.retention_policy_locked}\")\n",
    "    print(f\"Requester Pays: {bucket.requester_pays}\")\n",
    "    print(f\"Self Link: {bucket.self_link}\")\n",
    "    print(f\"Time Created: {bucket.time_created}\")\n",
    "    print(f\"Versioning Enabled: {bucket.versioning_enabled}\")\n",
    "    print(f\"Labels: {bucket.labels}\")\n",
    "\n",
    "bucket_metadata(bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mpd.slice.54000-54999.json\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import storage\n",
    "\n",
    "def list_blobs(bucket_name):\n",
    "    \"\"\"Lists all the blobs in the bucket.\"\"\"\n",
    "    # bucket_name = \"your-bucket-name\"\n",
    "\n",
    "    storage_client = storage.Client()\n",
    "\n",
    "    # Note: Client.list_blobs requires at least package version 1.17.0.\n",
    "    blobs = storage_client.list_blobs(bucket_name)\n",
    "\n",
    "    for blob in blobs:\n",
    "        print(blob.name)\n",
    "\n",
    "list_blobs(bucket_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!head -30 data/mpd.slice.54000-54999.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['info', 'playlists'])\n",
      "dict_keys(['generated_on', 'slice', 'version'])\n",
      "dict_keys(['name', 'collaborative', 'pid', 'modified_at', 'num_tracks', 'num_albums', 'num_followers', 'tracks', 'num_edits', 'duration_ms', 'num_artists'])\n",
      "dict_keys(['pos', 'artist_name', 'track_uri', 'artist_uri', 'track_name', 'album_uri', 'duration_ms', 'album_name'])\n"
     ]
    }
   ],
   "source": [
    "print(data.keys())\n",
    "print(data[\"info\"].keys())\n",
    "print(data[\"playlists\"][1].keys())\n",
    "print(data[\"playlists\"][1][\"tracks\"][1].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a BigQuery client object.\n",
    "client = bigquery.Client()\n",
    "\n",
    "# Set table_id to the ID of the table to create.\n",
    "table_id = \"alpine-beacon-336222.music.slices\" # \"project.dataset.table_name\"\n",
    "\n",
    "job_config = bigquery.LoadJobConfig(\n",
    "    schema=[\n",
    "        bigquery.SchemaField(\"info\", \"RECORD\", mode=\"REPEATED\",\n",
    "                            fields=(\n",
    "                                bigquery.SchemaField('generated_on', 'STRING'), # todo\n",
    "                                bigquery.SchemaField('slice', 'STRING'),\n",
    "                                bigquery.SchemaField('version', 'STRING')\n",
    "                            )),\n",
    "        bigquery.SchemaField(\"playlists\", \"RECORD\", mode=\"REPEATED\",\n",
    "                             fields=(\n",
    "                                bigquery.SchemaField(\"name\", \"STRING\"),\n",
    "                                bigquery.SchemaField(\"collaborative\", \"BOOLEAN\"),\n",
    "                                bigquery.SchemaField(\"pid\", \"INTEGER\"),\n",
    "                                bigquery.SchemaField(\"modified_at\", \"INTEGER\"),\n",
    "                                bigquery.SchemaField(\"num_tracks\", \"INTEGER\"),\n",
    "                                bigquery.SchemaField(\"num_albums\", \"INTEGER\"),\n",
    "                                bigquery.SchemaField(\"num_followers\", \"INTEGER\"),\n",
    "                                bigquery.SchemaField(\"tracks\", \"RECORD\", mode=\"REPEATED\",\n",
    "                                                    fields=(\n",
    "                                                        bigquery.SchemaField('pos', 'INTEGER'),\n",
    "                                                        bigquery.SchemaField('artist_name', 'STRING'),\n",
    "                                                        bigquery.SchemaField('track_uri', 'STRING'),\n",
    "                                                        bigquery.SchemaField('artist_uri', 'STRING'),\n",
    "                                                        bigquery.SchemaField('track_name', 'STRING'),\n",
    "                                                        bigquery.SchemaField('album_uri', 'STRING'),\n",
    "                                                        bigquery.SchemaField('duration_ms', 'INTEGER'),\n",
    "                                                        bigquery.SchemaField('album_name', 'STRING')\n",
    "                                                    )),\n",
    "                                bigquery.SchemaField(\"num_edits\", \"INTEGER\"),\n",
    "                                bigquery.SchemaField(\"duration_ms\", \"INTEGER\"),\n",
    "                                bigquery.SchemaField(\"num_artists\", \"INTEGER\")\n",
    "                             ))\n",
    "    ],\n",
    "    source_format=bigquery.SourceFormat.NEWLINE_DELIMITED_JSON,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "BadRequest",
     "evalue": "400 Error while reading data, error message: JSON table encountered too many errors, giving up. Rows: 1; errors: 1. Please look into the errors[] collection for more details.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadRequest\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-3ea63c6a4b3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mload_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Waits for the job to complete.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mClientError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/google/cloud/bigquery/job/base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, retry, timeout)\u001b[0m\n\u001b[1;32m    726\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mretry\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mDEFAULT_RETRY\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"retry\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mretry\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_AsyncJob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcancelled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/google/api_core/future/polling.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout, retry)\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0;31m# pylint: disable=raising-bad-type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0;31m# Pylint doesn't recognize that this is valid in this case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBadRequest\u001b[0m: 400 Error while reading data, error message: JSON table encountered too many errors, giving up. Rows: 1; errors: 1. Please look into the errors[] collection for more details."
     ]
    }
   ],
   "source": [
    "from botocore.exceptions import ClientError\n",
    "uri = \"gs://the-bourgeoisie/mpd.slice.54000-54999_hi.json\"\n",
    "\n",
    "load_job = client.load_table_from_uri(\n",
    "    uri, table_id,\n",
    "    job_config=job_config\n",
    ")  # Make an API request.\n",
    "\n",
    "try:\n",
    "    load_job.result()  # Waits for the job to complete.\n",
    "except ClientError as e:\n",
    "    print(load_job.errors)\n",
    "    raise e\n",
    "\n",
    "destination_table = client.get_table(table_id)  # Make an API request.\n",
    "print(\"Loaded {} rows.\".format(destination_table.num_rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'reason': 'invalid', 'location': 'gs://the-bourgeoisie/mpd.slice.54000-54999_hi.json', 'message': 'Error while reading data, error message: JSON table encountered too many errors, giving up. Rows: 1; errors: 1. Please look into the errors[] collection for more details.'} \n",
      "\n",
      "{'reason': 'invalid', 'message': 'Error while reading data, error message: JSON processing encountered too many errors, giving up. Rows: 1; errors: 1; max bad: 0; error percent: 0'} \n",
      "\n",
      "{'reason': 'invalid', 'location': 'gs://the-bourgeoisie/mpd.slice.54000-54999_hi.json', 'message': 'Error while reading data, error message: JSON parsing error in row starting at position 0: No such field: playlists.description.'} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for eRr in load_job.errors:\n",
    "    print(f\"{eRr} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
