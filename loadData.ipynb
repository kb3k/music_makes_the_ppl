{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"creativity is the residue of wasted time\" - Einstein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random fact corner\n",
    "\n",
    "# \"people from different cultures can agree that a song is angry, \n",
    "# but can differ on whether that feeling is positive or negative\"\n",
    "# - Cowen, https://greatergood.berkeley.edu/article/item/how_many_emotions_can_music_make_you_feel\n",
    "\n",
    "# valence -> culture specific; positive or negative values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndependencies\\n!python -m pip install --upgrade pip\\n!pip install --upgrade google-cloud\\n!pip install --upgrade google-cloud-bigquery\\n!pip install --upgrade google-cloud-storage\\n\\n!sed 's/ //g' data/mpd.slice.54000-54999.json | tr '\\n' ' '> data/mpd.slice.54000-54999_clean.json\\n\\n!gsutil -m cp data/mpd.slice.54000-54999_clean.json gs://the-bourgeoisie\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "dependencies\n",
    "!python -m pip install --upgrade pip\n",
    "!pip install --upgrade google-cloud\n",
    "!pip install --upgrade google-cloud-bigquery\n",
    "!pip install --upgrade google-cloud-storage\n",
    "\n",
    "!sed 's/ //g' data/mpd.slice.54000-54999.json | tr '\\n' ' '> data/mpd.slice.54000-54999_clean.json\n",
    "\n",
    "!gsutil -m cp data/mpd.slice.54000-54999_clean.json gs://the-bourgeoisie\n",
    "\"\"\"\n",
    "\n",
    "# source: https://big-data-demystified.ninja/2020/04/12/\n",
    "# how-to-debug-error-while-reading-data-error-message-\n",
    "# failed-to-parse-json-unexpected-end-of-string-unexpected-end-of-string-expected-key/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sed 's/ //g' data/mpd.slice.54000-54999.json | tr '\\n' ' '> data/mpd.slice.54000-54999_clean.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you experience problems with multiprocessing on MacOS, they might be related to https://bugs.python.org/issue33725. You can disable multiprocessing by editing your .boto config or by adding the following flag to your command: `-o \"GSUtil:parallel_process_count=1\"`. Note that multithreading is still available even if you disable multiprocessing.\n",
      "\n",
      "Copying file://data/mpd.slice.54000-54999_clean.json [Content-Type=application/json]...\n",
      "| [1/1 files][ 18.2 MiB/ 18.2 MiB] 100% Done                                    \n",
      "Operation completed over 1 objects/18.2 MiB.                                     \n"
     ]
    }
   ],
   "source": [
    "!gsutil -m cp data/mpd.slice.54000-54999_clean.json gs://the-bourgeoisie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n=== Process Overview ===\\n\\nUsing the code below I got some view into dataset, albeit the hardcoded index\\nprevented me from seeing some instances of the playlist object had an additional\\nfield, description. Being a spotify user I knew this wasn\\'t used a lot and was\\noptional. I found it by looking into the dataset from the GCS perspective and\\nusing the find/search. Tested and pretty sure I both sed and ts; the idea is to \\nuse the newer json format which seems to have lower memory storage by not using\\ntons of spacing and newline chars, even if it makes it prettier to read for human.\\nI suppose it\\'s meant to be read by machines most of the time.\\n\\n!head -30 data/mpd.slice.54000-54999.json\\n\\nLazy viewing dataset schema code (with hardcoded index value):\\nprint(data.keys())\\nprint(data[\"info\"].keys())\\nprint(data[\"playlists\"][1].keys())\\nprint(data[\"playlists\"][1][\"tracks\"][1].keys())\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "=== Process Overview ===\n",
    "\n",
    "Using the code below I got some view into dataset, albeit the hardcoded index\n",
    "prevented me from seeing some instances of the playlist object had an additional\n",
    "field, description. Being a spotify user I knew this wasn't used a lot and was\n",
    "optional. I found it by looking into the dataset from the GCS perspective and\n",
    "using the find/search. Tested and pretty sure I both sed and ts; the idea is to \n",
    "use the newer json format which seems to have lower memory storage by not using\n",
    "tons of spacing and newline chars, even if it makes it prettier to read for human.\n",
    "I suppose it's meant to be read by machines most of the time.\n",
    "\n",
    "!head -30 data/mpd.slice.54000-54999.json\n",
    "\n",
    "Lazy viewing dataset schema code (with hardcoded index value):\n",
    "print(data.keys())\n",
    "print(data[\"info\"].keys())\n",
    "print(data[\"playlists\"][1].keys())\n",
    "print(data[\"playlists\"][1][\"tracks\"][1].keys())\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from google.cloud import bigquery\n",
    "from google.cloud import storage\n",
    "\n",
    "from botocore.exceptions import ClientError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not secure but I'm lazy, steal what you must\n",
    "home = os.path.expanduser('~')\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=f\"{home}/.config/gcloud/alpine-beacon-336222-c6a1c087e3ef.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/mpd.slice.54000-54999.json\", \"r\") as the_jfile:\n",
    "    data = json.load(the_jfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top playlist name len found to be 66\n",
      "top track name len found to be 202\n",
      "top artist name len found to be 91\n",
      "top uri len found to be 37\n",
      "top album name len found to be 151\n"
     ]
    }
   ],
   "source": [
    "name_top_len = 0\n",
    "track_name_top_len = 0\n",
    "artist_top_len = 0\n",
    "uri_top_len = 0\n",
    "album_name_top_len = 0\n",
    "\n",
    "idx = 0\n",
    "\n",
    "#dict_keys(['name', 'collaborative', 'pid', 'modified_at', 'num_tracks', 'num_albums', 'num_followers', 'tracks', 'num_edits', 'duration_ms', 'num_artists'])\n",
    "\n",
    "while idx < len(data[\"playlists\"]):\n",
    "    for KEY, VAL in data[\"playlists\"][idx].items():\n",
    "#        print(f\"{KEY} : {VAL}\")\n",
    "        if KEY==\"name\":\n",
    "            cur_len = len(VAL)\n",
    "            if cur_len > name_top_len:\n",
    "                name_top_len = cur_len\n",
    "        elif KEY == \"tracks\":\n",
    "            tracks = data[\"playlists\"][idx][\"tracks\"]\n",
    "            for track in tracks:\n",
    "                cur_len = len(track[\"track_name\"])                \n",
    "                if cur_len > track_name_top_len:\n",
    "                    track_name_top_len = cur_len\n",
    "                cur_len = len(track[\"artist_name\"])\n",
    "                if cur_len > artist_top_len:\n",
    "                    artist_top_len = cur_len\n",
    "                cur_len = len(track[\"track_uri\"]) #36\n",
    "                if cur_len > uri_top_len:\n",
    "                    uri_top_len = cur_len\n",
    "                cur_len = len(track[\"artist_uri\"]) #37\n",
    "                if cur_len > uri_top_len:\n",
    "                    uri_top_len = cur_len\n",
    "                cur_len = len(track[\"album_uri\"]) #36\n",
    "                if cur_len > uri_top_len:\n",
    "                    uri_top_len = cur_len\n",
    "                cur_len = len(track[\"album_name\"])\n",
    "                if cur_len > album_name_top_len:\n",
    "                    album_name_top_len = cur_len\n",
    "    idx += 1\n",
    "\n",
    "#print(idx)\n",
    "        \n",
    "print(\"top playlist name len found to be {}\".format(name_top_len))\n",
    "print(\"top track name len found to be {}\".format(track_name_top_len))\n",
    "print(f\"top artist name len found to be {artist_top_len}\")\n",
    "print(f\"top uri len found to be {uri_top_len}\")\n",
    "print(\"top album name len found to be {}\".format(album_name_top_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpine-beacon-336222\n"
     ]
    }
   ],
   "source": [
    "# Construct a BigQuery client object.\n",
    "client = bigquery.Client()\n",
    "project = client.project\n",
    "\n",
    "print(project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets in project alpine-beacon-336222:\n",
      "\tmusic\n",
      "\tr_e_s_p_e_c_t\n"
     ]
    }
   ],
   "source": [
    "datasets = list(client.list_datasets())  # Make an API request.\n",
    "\n",
    "dsets=[]\n",
    "\n",
    "if datasets:\n",
    "    print(\"Datasets in project {}:\".format(project))\n",
    "    for dataset in datasets:\n",
    "        ds = dataset.dataset_id\n",
    "        dsets.append(ds)\n",
    "        print(\"\\t{}\".format(ds))\n",
    "else:\n",
    "    print(\"{} project does not contain any datasets.\".format(project))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "music is gucci\n"
     ]
    }
   ],
   "source": [
    "if \"music\" not in dsets:\n",
    "    dataset_id = \"{}.music\".format(client.project)\n",
    "    dataset = bigquery.Dataset(dataset_id)\n",
    "    dataset.location = \"US\"\n",
    "    dataset = client.create_dataset(dataset, timeout=30)  # Make an API request.\n",
    "    print(\"Created dataset {}.{}\".format(client.project, dataset.dataset_id))\n",
    "else:\n",
    "    print(\"music is gucci\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bucket_metadata(bucket_name):\n",
    "    \"\"\"Prints out a bucket's metadata.\"\"\"\n",
    "    # bucket_name = 'your-bucket-name'\n",
    "\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.get_bucket(bucket_name)\n",
    "\n",
    "    print(f\"ID: {bucket.id}\")\n",
    "    print(f\"Name: {bucket.name}\")\n",
    "    print(f\"Storage Class: {bucket.storage_class}\")\n",
    "    print(f\"Location: {bucket.location}\")\n",
    "    print(f\"Location Type: {bucket.location_type}\")\n",
    "    print(f\"Cors: {bucket.cors}\")\n",
    "    print(f\"Default Event Based Hold: {bucket.default_event_based_hold}\")\n",
    "    print(f\"Default KMS Key Name: {bucket.default_kms_key_name}\")\n",
    "    print(f\"Metageneration: {bucket.metageneration}\")\n",
    "    print(\n",
    "        f\"Public Access Prevention: {bucket.iam_configuration.public_access_prevention}\"\n",
    "    )\n",
    "    print(f\"Retention Effective Time: {bucket.retention_policy_effective_time}\")\n",
    "    print(f\"Retention Period: {bucket.retention_period}\")\n",
    "    print(f\"Retention Policy Locked: {bucket.retention_policy_locked}\")\n",
    "    print(f\"Requester Pays: {bucket.requester_pays}\")\n",
    "    print(f\"Self Link: {bucket.self_link}\")\n",
    "    print(f\"Time Created: {bucket.time_created}\")\n",
    "    print(f\"Versioning Enabled: {bucket.versioning_enabled}\")\n",
    "    print(f\"Labels: {bucket.labels}\")\n",
    "\n",
    "def list_blobs(bucket_name):\n",
    "    \"\"\"Lists all the blobs in the bucket.\"\"\"\n",
    "    # bucket_name = \"your-bucket-name\"\n",
    "\n",
    "    storage_client = storage.Client()\n",
    "\n",
    "    # Note: Client.list_blobs requires at least package version 1.17.0.\n",
    "    blobs = storage_client.list_blobs(bucket_name)\n",
    "\n",
    "    for blob in blobs:\n",
    "        print(blob.name)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====printing random metadata . . . \n",
      "ID: the-bourgeoisie\n",
      "Name: the-bourgeoisie\n",
      "Storage Class: STANDARD\n",
      "Location: US\n",
      "Location Type: multi-region\n",
      "Cors: []\n",
      "Default Event Based Hold: False\n",
      "Default KMS Key Name: None\n",
      "Metageneration: 1\n",
      "Public Access Prevention: inherited\n",
      "Retention Effective Time: None\n",
      "Retention Period: None\n",
      "Retention Policy Locked: None\n",
      "Requester Pays: False\n",
      "Self Link: https://www.googleapis.com/storage/v1/b/the-bourgeoisie\n",
      "Time Created: 2022-02-24 20:23:38.300000+00:00\n",
      "Versioning Enabled: False\n",
      "Labels: {}\n",
      "\n",
      "===printing blobs . . .\n",
      "mpd.slice.54000-54999.json\n",
      "mpd.slice.54000-54999_clean.json\n",
      "mpd.slice.54000-54999_giraff.json\n",
      "mpd.slice.54000-54999_hi.json\n",
      "mpd.slice.54000-54999_test.json\n"
     ]
    }
   ],
   "source": [
    "bucket_name=\"the-bourgeoisie\"\n",
    "\n",
    "print(\"=====printing random metadata . . . \")\n",
    "bucket_metadata(bucket_name)\n",
    "\n",
    "print(\"\\n===printing blobs . . .\")\n",
    "list_blobs(bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set table_id to the ID of the table to create.\n",
    "table_id = \"alpine-beacon-336222.music.slices\" # \"project.dataset.table_name\"\n",
    "\n",
    "job_config = bigquery.LoadJobConfig(\n",
    "    schema=[\n",
    "        bigquery.SchemaField(\"info\", \"RECORD\", mode=\"REPEATED\",\n",
    "                            fields=(\n",
    "                                bigquery.SchemaField('generated_on', 'STRING'), # todo\n",
    "                                bigquery.SchemaField('slice', 'STRING'),\n",
    "                                bigquery.SchemaField('version', 'STRING')\n",
    "                            )),\n",
    "        bigquery.SchemaField(\"playlists\", \"RECORD\", mode=\"REPEATED\",\n",
    "                             fields=(\n",
    "                                bigquery.SchemaField(\"name\", \"STRING\"),\n",
    "                                bigquery.SchemaField(\"collaborative\", \"BOOLEAN\"),\n",
    "                                bigquery.SchemaField(\"pid\", \"INTEGER\"),\n",
    "                                bigquery.SchemaField(\"modified_at\", \"INTEGER\"),\n",
    "                                bigquery.SchemaField(\"num_tracks\", \"INTEGER\"),\n",
    "                                bigquery.SchemaField(\"num_albums\", \"INTEGER\"),\n",
    "                                bigquery.SchemaField(\"num_followers\", \"INTEGER\"),\n",
    "                                bigquery.SchemaField(\"tracks\", \"RECORD\", mode=\"REPEATED\",\n",
    "                                                    fields=(\n",
    "                                                        bigquery.SchemaField('pos', 'INTEGER'),\n",
    "                                                        bigquery.SchemaField('artist_name', 'STRING'),\n",
    "                                                        bigquery.SchemaField('track_uri', 'STRING'),\n",
    "                                                        bigquery.SchemaField('artist_uri', 'STRING'),\n",
    "                                                        bigquery.SchemaField('track_name', 'STRING'),\n",
    "                                                        bigquery.SchemaField('album_uri', 'STRING'),\n",
    "                                                        bigquery.SchemaField('duration_ms', 'INTEGER'),\n",
    "                                                        bigquery.SchemaField('album_name', 'STRING')\n",
    "                                                    )),\n",
    "                                bigquery.SchemaField(\"num_edits\", \"INTEGER\"),\n",
    "                                bigquery.SchemaField(\"duration_ms\", \"INTEGER\"),\n",
    "                                bigquery.SchemaField(\"num_artists\", \"INTEGER\"),\n",
    "                                bigquery.SchemaField(\"description\", \"STRING\") # troublemaker\n",
    "                             ))\n",
    "    ],\n",
    "    source_format=bigquery.SourceFormat.NEWLINE_DELIMITED_JSON,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5 rows.\n"
     ]
    }
   ],
   "source": [
    "uri = \"gs://the-bourgeoisie/mpd.slice.54000-54999_clean.json\"\n",
    "\n",
    "load_job = client.load_table_from_uri(\n",
    "    uri, table_id,\n",
    "    job_config=job_config\n",
    ")  # Make an API request.\n",
    "\n",
    "try:\n",
    "    load_job.result()  # Waits for the job to complete.\n",
    "except ClientError as eek:\n",
    "    for eRr in load_job.errors:\n",
    "        print(f\"{eRr} \\n\")\n",
    "\n",
    "destination_table = client.get_table(table_id)  # Make an API request.\n",
    "print(\"Loaded {} rows.\".format(destination_table.num_rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
